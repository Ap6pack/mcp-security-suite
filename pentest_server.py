#!/usr/bin/env python3
"""
Penetration Testing MCP Server
Advanced tools for authorized penetration testing
"""

import asyncio
import json
import logging
import hashlib
import base64
import re
import struct
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import aiohttp
import socket
import ssl
from urllib.parse import urlparse, parse_qs

from mcp.server import Server
from mcp.server.stdio import stdio_server
import mcp.types as types

logger = logging.getLogger(__name__)

@dataclass
class PentestConfig:
    """Configuration for penetration testing tools"""
    target_scope: List[str]  # Authorized targets only
    test_intensity: str = "safe"  # safe, normal, aggressive
    enable_exploits: bool = False  # Require explicit permission
    log_all_attempts: bool = True
    max_threads: int = 10
    timeout: int = 30

class PentestServer:
    """Penetration Testing MCP Server"""
    
    def __init__(self, config: PentestConfig = None):
        self.server = Server("pentest-tools")
        self.config = config or PentestConfig(target_scope=[])
        self.test_results = {}
        self.setup_tools()
    
    def setup_tools(self):
        """Register penetration testing tools"""
        
        # Register the list_tools handler
        @self.server.list_tools()
        async def handle_list_tools() -> List[types.Tool]:
            """Return the list of available tools"""
            return [
                types.Tool(
                    name="vulnerability_scan",
                    description="Perform vulnerability scanning on authorized target",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "target": {
                                "type": "string",
                                "description": "Target URL or IP (must be in scope)"
                            },
                            "scan_type": {
                                "type": "string",
                                "description": "basic, comprehensive, or stealth",
                                "default": "basic"
                            },
                            "check_auth": {
                                "type": "boolean",
                                "description": "Test for authentication issues",
                                "default": True
                            },
                            "check_injection": {
                                "type": "boolean",
                                "description": "Test for injection vulnerabilities",
                                "default": True
                            },
                            "check_xss": {
                                "type": "boolean",
                                "description": "Test for XSS vulnerabilities",
                                "default": True
                            }
                        },
                        "required": ["target"]
                    }
                ),
                types.Tool(
                    name="fuzzing_test",
                    description="Perform fuzzing tests on web applications",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "target_url": {
                                "type": "string",
                                "description": "Target URL to fuzz"
                            },
                            "fuzz_type": {
                                "type": "string",
                                "description": "parameter, header, or path fuzzing",
                                "default": "parameter"
                            },
                            "wordlist": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "Custom fuzzing payloads"
                            },
                            "methods": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "HTTP methods to test"
                            }
                        },
                        "required": ["target_url"]
                    }
                ),
                types.Tool(
                    name="password_audit",
                    description="Audit password hashes (for authorized testing only)",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "hash_list": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "List of password hashes to audit"
                            },
                            "hash_type": {
                                "type": "string",
                                "description": "Hash type (md5, sha1, sha256, bcrypt, auto)",
                                "default": "auto"
                            },
                            "check_common": {
                                "type": "boolean",
                                "description": "Check against common passwords",
                                "default": True
                            },
                            "check_leaked": {
                                "type": "boolean",
                                "description": "Check against leaked password databases",
                                "default": True
                            }
                        }
                    }
                ),
                types.Tool(
                    name="exploit_framework",
                    description="Exploit framework for testing verified vulnerabilities",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "vulnerability_type": {
                                "type": "string",
                                "description": "Type of vulnerability to test"
                            },
                            "target": {
                                "type": "string",
                                "description": "Target system (must be authorized)"
                            },
                            "payload_type": {
                                "type": "string",
                                "description": "test, poc, or custom",
                                "default": "test"
                            },
                            "verify_only": {
                                "type": "boolean",
                                "description": "Only verify, don't exploit",
                                "default": True
                            }
                        },
                        "required": ["vulnerability_type", "target"]
                    }
                ),
                types.Tool(
                    name="web_shell_detector",
                    description="Detect potential web shells in authorized systems",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "target_directory": {
                                "type": "string",
                                "description": "Directory to scan"
                            },
                            "scan_depth": {
                                "type": "integer",
                                "description": "Recursion depth",
                                "default": 3
                            },
                            "check_patterns": {
                                "type": "boolean",
                                "description": "Check for known shell patterns",
                                "default": True
                            },
                            "check_behaviors": {
                                "type": "boolean",
                                "description": "Check for shell-like behaviors",
                                "default": True
                            }
                        },
                        "required": ["target_directory"]
                    }
                ),
                types.Tool(
                    name="privilege_escalation_check",
                    description="Check for privilege escalation vectors",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "target_os": {
                                "type": "string",
                                "description": "Operating system (linux, windows)",
                                "default": "linux"
                            },
                            "check_type": {
                                "type": "string",
                                "description": "all, misconfig, kernel, service",
                                "default": "all"
                            },
                            "user_context": {
                                "type": "string",
                                "description": "Current user context"
                            }
                        }
                    }
                ),
                types.Tool(
                    name="analyze_business_impact",
                    description="Analyze security findings for business impact and risk prioritization",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "findings": {
                                "type": "array",
                                "items": {"type": "object"},
                                "description": "List of security findings to analyze"
                            },
                            "asset_context": {
                                "type": "object",
                                "description": "Additional business context for assets"
                            }
                        },
                        "required": ["findings"]
                    }
                )
            ]
        
        # Register the call_tool handler
        @self.server.call_tool()
        async def handle_call_tool(name: str, arguments: dict) -> List[types.TextContent]:
            """Handle tool calls"""
            
            if name == "vulnerability_scan":
                result = await self._vulnerability_scan(
                    arguments.get("target", ""),
                    arguments.get("scan_type", "basic"),
                    arguments.get("check_auth", True),
                    arguments.get("check_injection", True),
                    arguments.get("check_xss", True)
                )
            elif name == "fuzzing_test":
                result = await self._fuzzing_test(
                    arguments.get("target_url", ""),
                    arguments.get("fuzz_type", "parameter"),
                    arguments.get("wordlist"),
                    arguments.get("methods")
                )
            elif name == "password_audit":
                result = await self._password_audit(
                    arguments.get("hash_list"),
                    arguments.get("hash_type", "auto"),
                    arguments.get("check_common", True),
                    arguments.get("check_leaked", True)
                )
            elif name == "exploit_framework":
                result = await self._exploit_framework(
                    arguments.get("vulnerability_type", ""),
                    arguments.get("target", ""),
                    arguments.get("payload_type", "test"),
                    arguments.get("verify_only", True)
                )
            elif name == "web_shell_detector":
                result = await self._web_shell_detector(
                    arguments.get("target_directory", ""),
                    arguments.get("scan_depth", 3),
                    arguments.get("check_patterns", True),
                    arguments.get("check_behaviors", True)
                )
            elif name == "privilege_escalation_check":
                result = await self._privilege_escalation_check(
                    arguments.get("target_os", "linux"),
                    arguments.get("check_type", "all"),
                    arguments.get("user_context")
                )
            elif name == "analyze_business_impact":
                result = await self._analyze_business_impact(
                    arguments.get("findings", [])
                )
            else:
                result = {"error": f"Unknown tool: {name}"}
            
            return [types.TextContent(type="text", text=json.dumps(result, indent=2))]
    
    async def _vulnerability_scan(
        self,
        target: str,
        scan_type: str = "basic",
        check_auth: bool = True,
        check_injection: bool = True,
        check_xss: bool = True
    ) -> Dict[str, Any]:
        """Perform vulnerability scanning on authorized target"""
        if not self._is_in_scope(target):
            return {"error": "Target not in authorized scope"}
        
        scan_results = {
            'target': target,
            'timestamp': datetime.now().isoformat(),
            'scan_type': scan_type,
            'vulnerabilities': [],
            'risk_score': 0,
            'recommendations': []
        }
        
        # Authentication checks
        if check_auth:
            auth_vulns = await self._check_authentication(target)
            scan_results['vulnerabilities'].extend(auth_vulns)
        
        # Injection testing (SQL, Command, LDAP)
        if check_injection:
            injection_vulns = await self._test_injections(target)
            scan_results['vulnerabilities'].extend(injection_vulns)
        
        # XSS testing
        if check_xss:
            xss_vulns = await self._test_xss(target)
            scan_results['vulnerabilities'].extend(xss_vulns)
        
        # Additional checks based on scan type
        if scan_type in ['comprehensive', 'aggressive']:
            # Directory traversal
            traversal_vulns = await self._test_directory_traversal(target)
            scan_results['vulnerabilities'].extend(traversal_vulns)
            
            # SSRF testing
            ssrf_vulns = await self._test_ssrf(target)
            scan_results['vulnerabilities'].extend(ssrf_vulns)
            
            # XXE testing
            xxe_vulns = await self._test_xxe(target)
            scan_results['vulnerabilities'].extend(xxe_vulns)
        
        # Calculate risk score
        scan_results['risk_score'] = self._calculate_risk_score(scan_results['vulnerabilities'])
        
        # Generate recommendations
        scan_results['recommendations'] = self._generate_recommendations(scan_results['vulnerabilities'])
        
        # Store results
        self.test_results[target] = scan_results
        
        return scan_results
    
    async def _fuzzing_test(
        self,
        target_url: str,
        fuzz_type: str = "parameter",
        wordlist: List[str] = None,
        methods: List[str] = None
    ) -> Dict[str, Any]:
        """Perform fuzzing tests on web applications"""
        if not self._is_in_scope(target_url):
            return {"error": "Target not in authorized scope"}
        
        if methods is None:
            methods = ['GET', 'POST']
        
        if wordlist is None:
            wordlist = self._get_default_fuzz_list(fuzz_type)
        
        fuzz_results = {
            'target': target_url,
            'fuzz_type': fuzz_type,
            'timestamp': datetime.now().isoformat(),
            'findings': [],
            'error_signatures': [],
            'interesting_responses': []
        }
        
        async with aiohttp.ClientSession() as session:
            for method in methods:
                for payload in wordlist[:100]:  # Limit payloads
                    if fuzz_type == "parameter":
                        result = await self._fuzz_parameters(session, target_url, method, payload)
                    elif fuzz_type == "header":
                        result = await self._fuzz_headers(session, target_url, method, payload)
                    elif fuzz_type == "path":
                        result = await self._fuzz_path(session, target_url, method, payload)
                    
                    if result and result['interesting']:
                        fuzz_results['findings'].append(result)
        
        return fuzz_results
    
    async def _password_audit(
        self,
        hash_list: List[str] = None,
        hash_type: str = "auto",
        check_common: bool = True,
        check_leaked: bool = True
    ) -> Dict[str, Any]:
        """Audit password hashes (for authorized testing only)"""
        audit_results = {
            'timestamp': datetime.now().isoformat(),
            'total_hashes': len(hash_list) if hash_list else 0,
            'cracked': [],
            'weak_passwords': [],
            'leaked_passwords': [],
            'recommendations': []
        }
        
        if not hash_list:
            return audit_results
        
        # Detect hash type if auto
        if hash_type == "auto":
            hash_type = self._detect_hash_type(hash_list[0])
        
        # Check against common passwords
        if check_common:
            common_passwords = self._get_common_passwords()
            for pwd_hash in hash_list:
                for password in common_passwords:
                    if self._verify_hash(password, pwd_hash, hash_type):
                        audit_results['weak_passwords'].append({
                            'hash': pwd_hash,
                            'password': '[REDACTED]',  # Don't expose actual password
                            'category': 'common'
                        })
                        break
        
        # Check against leaked databases (using HIBP or similar)
        if check_leaked:
            for pwd_hash in hash_list:
                if await self._check_pwned_password(pwd_hash):
                    audit_results['leaked_passwords'].append(pwd_hash)
        
        # Generate recommendations
        if audit_results['weak_passwords']:
            audit_results['recommendations'].append("Enforce stronger password policies")
        if audit_results['leaked_passwords']:
            audit_results['recommendations'].append("Force password reset for leaked credentials")
        
        return audit_results
    
    async def _exploit_framework(
        self,
        vulnerability_type: str,
        target: str,
        payload_type: str = "test",
        verify_only: bool = True
    ) -> Dict[str, Any]:
        """Exploit framework for testing verified vulnerabilities"""
        if not self.config.enable_exploits:
            return {"error": "Exploitation disabled. Enable in config with explicit permission."}
        
        if not self._is_in_scope(target):
            return {"error": "Target not in authorized scope"}
        
        exploit_results = {
            'target': target,
            'vulnerability': vulnerability_type,
            'timestamp': datetime.now().isoformat(),
            'verified': False,
            'poc': None,
            'impact': None,
            'remediation': None
        }
        
        # Map vulnerability types to testing functions
        exploit_map = {
            'sqli': self._exploit_sqli,
            'xss': self._exploit_xss,
            'rce': self._exploit_rce,
            'lfi': self._exploit_lfi,
            'xxe': self._exploit_xxe,
            'ssrf': self._exploit_ssrf,
            'deserialization': self._exploit_deserialization
        }
        
        if vulnerability_type in exploit_map:
            if verify_only:
                # Only verify the vulnerability exists
                exploit_results['verified'] = await exploit_map[vulnerability_type](
                    target, verify_only=True
                )
            else:
                # Generate PoC
                poc_result = await exploit_map[vulnerability_type](
                    target, verify_only=False, payload_type=payload_type
                )
                exploit_results.update(poc_result)
        
        return exploit_results
    
    async def _web_shell_detector(
        self,
        target_directory: str,
        scan_depth: int = 3,
        check_patterns: bool = True,
        check_behaviors: bool = True
    ) -> Dict[str, Any]:
        """Detect potential web shells in authorized systems"""
        detection_results = {
            'target': target_directory,
            'timestamp': datetime.now().isoformat(),
            'suspicious_files': [],
            'confirmed_shells': [],
            'indicators': []
        }
        
        # Common web shell signatures
        shell_signatures = [
            r'eval\s*\(\s*\$_(?:GET|POST|REQUEST)',
            r'system\s*\(\s*\$_',
            r'exec\s*\(\s*\$_',
            r'passthru\s*\(\s*\$_',
            r'shell_exec\s*\(\s*\$_',
            r'base64_decode\s*\([^)]*\$_',
            r'\\x[0-9a-f]{2}',  # Hex encoding
            r'chr\s*\(\s*\d+\s*\)',  # Chr encoding
            r'assert\s*\(\s*\$_',
            r'preg_replace.*\/e',  # PHP /e modifier
            r'create_function',
            r'@?include\s*\(\s*\$_',
            r'@?require\s*\(\s*\$_'
        ]
        
        # Behavioral patterns
        behavior_patterns = [
            'file upload functionality',
            'command execution',
            'database access',
            'reverse connection',
            'privilege escalation'
        ]
        
        # Scan would be implemented here
        # This is a demonstration structure
        
        return detection_results
    
    async def _privilege_escalation_check(
        self,
        target_os: str = "linux",
        check_type: str = "all",
        user_context: str = None
    ) -> Dict[str, Any]:
        """Check for privilege escalation vectors"""
        priv_esc_results = {
            'target_os': target_os,
            'timestamp': datetime.now().isoformat(),
            'current_user': user_context,
            'escalation_vectors': [],
            'exploitable': [],
            'recommendations': []
        }
        
        if target_os == "linux":
            checks = {
                'suid_binaries': self._check_suid_binaries,
                'sudo_misconfig': self._check_sudo_misconfig,
                'kernel_exploits': self._check_kernel_exploits,
                'cron_jobs': self._check_cron_jobs,
                'writable_paths': self._check_writable_paths,
                'capabilities': self._check_capabilities
            }
        elif target_os == "windows":
            checks = {
                'unquoted_paths': self._check_unquoted_paths,
                'weak_permissions': self._check_weak_permissions,
                'registry_keys': self._check_registry_keys,
                'scheduled_tasks': self._check_scheduled_tasks,
                'token_privs': self._check_token_privileges
            }
        
        # Run checks based on type
        if check_type == "all":
            for check_name, check_func in checks.items():
                result = await check_func()
                if result:
                    priv_esc_results['escalation_vectors'].append(result)
        
        return priv_esc_results
    
    # Helper methods for vulnerability testing
    async def _check_authentication(self, target: str) -> List[Dict[str, Any]]:
        """Check for authentication vulnerabilities"""
        vulns = []
        
        # Check for default credentials
        default_creds = [
            ('admin', 'admin'),
            ('admin', 'password'),
            ('root', 'root'),
            ('test', 'test')
        ]
        
        # Check for weak session management
        session_checks = [
            'predictable_session_ids',
            'session_fixation',
            'missing_csrf_tokens'
        ]
        
        # Would implement actual checks here
        
        return vulns
    
    async def _test_injections(self, target: str) -> List[Dict[str, Any]]:
        """Test for injection vulnerabilities"""
        vulns = []
        
        # SQL injection payloads
        sqli_payloads = [
            "' OR '1'='1",
            "1' AND '1'='2",
            "' UNION SELECT NULL--",
            "1' ORDER BY 1--",
            "' AND 1=CONVERT(int, @@version)--"
        ]
        
        # Command injection payloads
        cmd_payloads = [
            "; id",
            "| id",
            "`id`",
            "$(id)",
            "; sleep 5"
        ]
        
        # Test each payload
        async with aiohttp.ClientSession() as session:
            for payload in sqli_payloads[:3]:  # Limited testing
                response = await self._send_payload(session, target, payload)
                if self._detect_sqli_error(response):
                    vulns.append({
                        'type': 'SQL Injection',
                        'severity': 'high',
                        'payload': payload,
                        'evidence': 'Error message detected'
                    })
                    break
        
        return vulns
    
    async def _test_xss(self, target: str) -> List[Dict[str, Any]]:
        """Test for XSS vulnerabilities"""
        vulns = []
        
        # XSS payloads
        xss_payloads = [
            '<script>alert(1)</script>',
            '<img src=x onerror=alert(1)>',
            '"><script>alert(1)</script>',
            "';alert(1);//",
            '<svg onload=alert(1)>'
        ]
        
        # Would implement actual testing here
        
        return vulns
    
    async def _test_directory_traversal(self, target: str) -> List[Dict[str, Any]]:
        """Test for directory traversal vulnerabilities"""
        vulns = []
        
        # Directory traversal payloads
        traversal_payloads = [
            '../../../etc/passwd',
            '..\\..\\..\\windows\\system32\\config\\sam',
            '....//....//....//etc/passwd',
            '%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd'
        ]
        
        return vulns
    
    async def _test_ssrf(self, target: str) -> List[Dict[str, Any]]:
        """Test for SSRF vulnerabilities"""
        vulns = []
        
        # SSRF test payloads
        ssrf_payloads = [
            'http://localhost',
            'http://127.0.0.1',
            'http://169.254.169.254',  # AWS metadata
            'file:///etc/passwd'
        ]
        
        return vulns
    
    async def _test_xxe(self, target: str) -> List[Dict[str, Any]]:
        """Test for XXE vulnerabilities"""
        vulns = []
        
        # XXE payloads
        xxe_payload = """<?xml version="1.0" encoding="UTF-8"?>
        <!DOCTYPE foo [
        <!ELEMENT foo ANY >
        <!ENTITY xxe SYSTEM "file:///etc/passwd" >]>
        <foo>&xxe;</foo>"""
        
        return vulns
    
    def _calculate_risk_score(self, vulnerabilities: List[Dict]) -> int:
        """Calculate overall risk score"""
        score = 0
        severity_scores = {'critical': 10, 'high': 7, 'medium': 4, 'low': 1}
        
        for vuln in vulnerabilities:
            score += severity_scores.get(vuln.get('severity', 'low'), 1)
        
        return min(score, 100)  # Cap at 100
    
    def _generate_recommendations(self, vulnerabilities: List[Dict]) -> List[str]:
        """Generate security recommendations"""
        recommendations = []
        vuln_types = set(v.get('type') for v in vulnerabilities)
        
        if 'SQL Injection' in vuln_types:
            recommendations.append("Implement parameterized queries and input validation")
        if 'XSS' in vuln_types:
            recommendations.append("Implement output encoding and Content Security Policy")
        if 'Authentication' in vuln_types:
            recommendations.append("Enforce strong password policies and MFA")
        
        return recommendations
    
    def _is_in_scope(self, target: str) -> bool:
        """Check if target is in authorized scope"""
        if not self.config.target_scope:
            return False  # No scope defined, deny all
        
        parsed = urlparse(target)
        hostname = parsed.hostname or target
        
        for scope_item in self.config.target_scope:
            if scope_item in hostname or hostname in scope_item:
                return True
        
        return False
    
    def _get_default_fuzz_list(self, fuzz_type: str) -> List[str]:
        """Get default fuzzing wordlist"""
        if fuzz_type == "parameter":
            return [
                "test", "admin", "' OR '1'='1", "<script>", 
                "../../../etc/passwd", "{{7*7}}", "${7*7}"
            ]
        elif fuzz_type == "header":
            return [
                "' OR '1'='1", "../../../", "<script>alert(1)</script>",
                "127.0.0.1", "localhost"
            ]
        elif fuzz_type == "path":
            return [
                "admin", "backup", ".git", ".env", "config",
                "api", "debug", "test"
            ]
        return []
    
    async def _fuzz_parameters(self, session, url, method, payload):
        """Fuzz URL parameters"""
        try:
            if method == "GET":
                test_url = f"{url}?test={payload}"
                async with session.get(test_url, timeout=5) as response:
                    return self._analyze_fuzz_response(response, payload)
            elif method == "POST":
                data = {'test': payload}
                async with session.post(url, data=data, timeout=5) as response:
                    return self._analyze_fuzz_response(response, payload)
        except:
            return None
    
    async def _fuzz_headers(self, session, url, method, payload):
        """Fuzz HTTP headers"""
        headers = {
            'User-Agent': payload,
            'X-Forwarded-For': payload,
            'Referer': payload
        }
        try:
            async with session.request(method, url, headers=headers, timeout=5) as response:
                return self._analyze_fuzz_response(response, payload)
        except:
            return None
    
    async def _fuzz_path(self, session, url, method, payload):
        """Fuzz URL paths"""
        parsed = urlparse(url)
        test_url = f"{parsed.scheme}://{parsed.netloc}/{payload}"
        try:
            async with session.request(method, test_url, timeout=5) as response:
                if response.status != 404:
                    return {
                        'payload': payload,
                        'status': response.status,
                        'interesting': True
                    }
        except:
            return None
    
    def _analyze_fuzz_response(self, response, payload):
        """Analyze fuzzing response for interesting patterns"""
        interesting = False
        
        # Check for errors or interesting status codes
        if response.status in [500, 403, 401]:
            interesting = True
        
        # Would check response body for error messages
        
        return {
            'payload': payload,
            'status': response.status,
            'interesting': interesting
        }
    
    def _detect_hash_type(self, hash_string: str) -> str:
        """Detect password hash type"""
        hash_len = len(hash_string)
        
        if hash_len == 32:
            return "md5"
        elif hash_len == 40:
            return "sha1"
        elif hash_len == 64:
            return "sha256"
        elif hash_string.startswith("$2"):
            return "bcrypt"
        
        return "unknown"
    
    def _verify_hash(self, password: str, hash_string: str, hash_type: str) -> bool:
        """Verify if password matches hash"""
        if hash_type == "md5":
            return hashlib.md5(password.encode()).hexdigest() == hash_string
        elif hash_type == "sha1":
            return hashlib.sha1(password.encode()).hexdigest() == hash_string
        elif hash_type == "sha256":
            return hashlib.sha256(password.encode()).hexdigest() == hash_string
        
        return False
    
    def _get_common_passwords(self) -> List[str]:
        """Get list of common passwords"""
        return [
            "password", "123456", "password123", "admin", "letmein",
            "qwerty", "monkey", "dragon", "baseball", "iloveyou"
        ]
    
    async def _check_pwned_password(self, pwd_hash: str) -> bool:
        """Check if password hash appears in breach databases"""
        # Would integrate with HIBP API
        return False
    
    def _detect_sqli_error(self, response) -> bool:
        """Detect SQL injection errors in response"""
        if not response:
            return False
        
        error_patterns = [
            "SQL syntax",
            "mysql_fetch",
            "ORA-[0-9]+",
            "PostgreSQL",
            "SQLite",
            "Microsoft SQL Server"
        ]
        
        # Would check response body for patterns
        return False
    
    async def _send_payload(self, session, target, payload):
        """Send payload to target"""
        try:
            async with session.get(f"{target}?input={payload}", timeout=5) as response:
                return await response.text()
        except:
            return None
    
    # Stub methods for exploit framework
    async def _exploit_sqli(self, target, verify_only=True, payload_type=None):
        """SQL injection exploitation"""
        return {'verified': False, 'poc': 'SQLi PoC placeholder'}
    
    async def _exploit_xss(self, target, verify_only=True, payload_type=None):
        """XSS exploitation"""
        return {'verified': False, 'poc': 'XSS PoC placeholder'}
    
    async def _exploit_rce(self, target, verify_only=True, payload_type=None):
        """RCE exploitation"""
        return {'verified': False, 'poc': 'RCE PoC placeholder'}
    
    async def _exploit_lfi(self, target, verify_only=True, payload_type=None):
        """LFI exploitation"""
        return {'verified': False, 'poc': 'LFI PoC placeholder'}
    
    async def _exploit_xxe(self, target, verify_only=True, payload_type=None):
        """XXE exploitation"""
        return {'verified': False, 'poc': 'XXE PoC placeholder'}
    
    async def _exploit_ssrf(self, target, verify_only=True, payload_type=None):
        """SSRF exploitation"""
        return {'verified': False, 'poc': 'SSRF PoC placeholder'}
    
    async def _exploit_deserialization(self, target, verify_only=True, payload_type=None):
        """Deserialization exploitation"""
        return {'verified': False, 'poc': 'Deserialization PoC placeholder'}
    
    # Stub methods for privilege escalation checks
    async def _check_suid_binaries(self):
        """Check for exploitable SUID binaries"""
        return None
    
    async def _check_sudo_misconfig(self):
        """Check for sudo misconfigurations"""
        return None
    
    async def _check_kernel_exploits(self):
        """Check for kernel exploits"""
        return None
    
    async def _check_cron_jobs(self):
        """Check for exploitable cron jobs"""
        return None
    
    async def _check_writable_paths(self):
        """Check for writable system paths"""
        return None
    
    async def _check_capabilities(self):
        """Check for dangerous capabilities"""
        return None
    
    async def _check_unquoted_paths(self):
        """Check for unquoted service paths"""
        return None
    
    async def _check_weak_permissions(self):
        """Check for weak file permissions"""
        return None
    
    async def _check_registry_keys(self):
        """Check for writable registry keys"""
        return None
    
    async def _check_scheduled_tasks(self):
        """Check for exploitable scheduled tasks"""
        return None
    
    async def _check_token_privileges(self):
        """Check for exploitable token privileges"""
        return None
    
    async def _analyze_business_impact(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze penetration testing findings for business impact and exploitability"""
        
        try:
            enhanced_findings = []
            summary_stats = {
                'total_findings': len(findings),
                'critical_vulnerabilities': 0,
                'high_risk_exploits': 0,
                'privilege_escalations': 0,
                'data_exposure_risks': 0,
                'authentication_bypasses': 0,
                'exploit_chains_possible': 0,
                'business_impact_score': 0,
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            total_business_impact = 0
            
            for finding in findings:
                try:
                    # Pentest-specific business impact analysis
                    enhanced_finding = await self._analyze_pentest_finding_impact(finding)
                    enhanced_findings.append(enhanced_finding)
                    
                    # Update summary stats
                    risk_level = enhanced_finding.get('exploitability_level', 'low')
                    if risk_level == 'critical':
                        summary_stats['critical_vulnerabilities'] += 1
                    elif risk_level == 'high':
                        summary_stats['high_risk_exploits'] += 1
                    
                    if enhanced_finding.get('enables_privilege_escalation', False):
                        summary_stats['privilege_escalations'] += 1
                    
                    if enhanced_finding.get('exposes_sensitive_data', False):
                        summary_stats['data_exposure_risks'] += 1
                    
                    if enhanced_finding.get('bypasses_authentication', False):
                        summary_stats['authentication_bypasses'] += 1
                    
                    if enhanced_finding.get('exploit_chain_potential', 0) > 0:
                        summary_stats['exploit_chains_possible'] += 1
                    
                    total_business_impact += enhanced_finding.get('business_impact_score', 0)

                except Exception as e:
                    logger.error(f"Failed to analyze pentest finding: {str(e)}")
                    enhanced_findings.append({
                        **finding,
                        'pentest_analysis_error': str(e),
                        'exploitability_level': 'unknown'
                    })
            
            # Calculate overall business impact score
            if findings:
                summary_stats['business_impact_score'] = round(total_business_impact / len(findings), 2)
            
            return {
                'enhanced_findings': enhanced_findings,
                'summary': summary_stats,
                'vulnerability_assessment_summary': self._generate_pentest_summary(summary_stats),
                'recommended_actions': self._generate_pentest_action_plan(enhanced_findings),
                'exploit_analysis_enabled': True
            }
    
        except Exception as e:
            logger.error(f"Pentest business impact analysis failed: {str(e)}")
            return {
                'error': f'Pentest business impact analysis failed: {str(e)}',
                'enhanced_findings': findings,  # Return original findings
                'analysis_timestamp': datetime.now().isoformat()
            }
    
    async def _analyze_pentest_finding_impact(self, finding: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze individual pentest finding for business impact and exploitability"""
        
        vuln_type = finding.get('type', finding.get('vulnerability_type', 'unknown'))
        severity = finding.get('severity', 'low').lower()
        target = finding.get('target', finding.get('asset', 'unknown'))
        
        # Calculate exploitability score
        exploit_score = 0
        impact_factors = []
        
        # Base score from severity
        severity_scores = {'critical': 8, 'high': 6, 'medium': 4, 'low': 2, 'info': 1}
        exploit_score += severity_scores.get(severity, 2)
        
        # Vulnerability type impact
        vuln_impact = self._assess_vulnerability_impact(vuln_type, finding)
        exploit_score += vuln_impact
        if vuln_impact > 2:
            impact_factors.append(f"High-impact vulnerability type: {vuln_type}")
        
        # Authentication bypass potential
        auth_bypass = self._assess_authentication_bypass(vuln_type, finding)
        if auth_bypass:
            exploit_score += 3
            impact_factors.append("Enables authentication bypass")
        
        # Privilege escalation potential
        privesc_potential = self._assess_privilege_escalation(vuln_type, finding)
        if privesc_potential:
            exploit_score += 4
            impact_factors.append("Privilege escalation possible")
        
        # Data exposure risk
        data_exposure = self._assess_data_exposure(vuln_type, target, finding)
        if data_exposure > 0:
            exploit_score += data_exposure
            impact_factors.append("Sensitive data exposure risk")
        
        # Remote code execution potential
        rce_potential = self._assess_rce_potential(vuln_type, finding)
        if rce_potential:
            exploit_score += 5
            impact_factors.append("Remote code execution possible")
        
        # Network lateral movement potential
        lateral_movement = self._assess_lateral_movement(target, finding)
        if lateral_movement > 0:
            exploit_score += lateral_movement
            impact_factors.append("Network lateral movement potential")
        
        # Determine exploitability level
        if exploit_score >= 15:
            exploitability_level = 'critical'
        elif exploit_score >= 10:
            exploitability_level = 'high'
        elif exploit_score >= 6:
            exploitability_level = 'medium'
        else:
            exploitability_level = 'low'
        
        # Calculate business impact score (1-10)
        business_impact_score = min(exploit_score / 2, 10)
        
        # Generate exploit chain assessment
        exploit_chain_potential = self._assess_exploit_chain_potential(vuln_type, finding)
        
        # Generate remediation guidance
        remediation = self._generate_pentest_remediation(vuln_type, exploitability_level, finding)
        
        return {
            **finding,
            'exploit_score': exploit_score,
            'exploitability_level': exploitability_level,
            'business_impact_score': business_impact_score,
            'impact_factors': impact_factors,
            'enables_privilege_escalation': privesc_potential,
            'bypasses_authentication': auth_bypass,
            'enables_rce': rce_potential,
            'exposes_sensitive_data': data_exposure > 0,
            'exploit_chain_potential': exploit_chain_potential,
            'remediation_priority': self._get_remediation_priority(exploitability_level),
            'remediation_guidance': remediation,
            'penetration_test_impact': self._describe_pentest_impact(exploitability_level, vuln_type)
        }
    
    def _assess_vulnerability_impact(self, vuln_type: str, finding: Dict[str, Any]) -> int:
        """Assess the impact level of vulnerability type"""
        vuln_lower = vuln_type.lower()
        
        # Critical impact vulnerabilities
        if any(critical in vuln_lower for critical in ['rce', 'remote_code_execution', 'command_injection', 'deserialization']):
            return 5
        
        # High impact vulnerabilities  
        if any(high in vuln_lower for high in ['sql_injection', 'xxe', 'ssrf', 'file_upload', 'directory_traversal']):
            return 4
        
        # Medium impact vulnerabilities
        if any(medium in vuln_lower for medium in ['xss', 'csrf', 'open_redirect', 'auth_bypass', 'privilege_escalation']):
            return 3
        
        # Low impact vulnerabilities
        if any(low in vuln_lower for low in ['information_disclosure', 'misconfiguration', 'weak_crypto']):
            return 2
        
        return 1
    
    def _assess_authentication_bypass(self, vuln_type: str, finding: Dict[str, Any]) -> bool:
        """Check if vulnerability enables authentication bypass"""
        vuln_lower = vuln_type.lower()
        auth_bypass_indicators = ['auth_bypass', 'authentication_bypass', 'login_bypass', 'jwt_bypass', 'session_fixation']
        
        if any(indicator in vuln_lower for indicator in auth_bypass_indicators):
            return True
        
        # Check in description or details
        description = finding.get('description', '').lower()
        if any(indicator in description for indicator in auth_bypass_indicators):
            return True
        
        return False
    
    def _assess_privilege_escalation(self, vuln_type: str, finding: Dict[str, Any]) -> bool:
        """Check if vulnerability enables privilege escalation"""
        vuln_lower = vuln_type.lower()
        privesc_indicators = ['privilege_escalation', 'privesc', 'sudo', 'setuid', 'buffer_overflow']
        
        if any(indicator in vuln_lower for indicator in privesc_indicators):
            return True
        
        # Check for specific conditions
        if 'command_injection' in vuln_lower and finding.get('context', '').lower() in ['admin', 'root', 'system']:
            return True
        
        return False
    
    def _assess_data_exposure(self, vuln_type: str, target: str, finding: Dict[str, Any]) -> int:
        """Assess data exposure risk level (0-3)"""
        vuln_lower = vuln_type.lower()
        target_lower = target.lower()
        
        exposure_score = 0
        
        # High data exposure vulnerabilities
        if any(high in vuln_lower for high in ['sql_injection', 'directory_traversal', 'file_inclusion', 'xxe']):
            exposure_score += 2
        
        # Medium data exposure
        if any(medium in vuln_lower for medium in ['information_disclosure', 'path_traversal', 'backup_disclosure']):
            exposure_score += 1
        
        # Target contains sensitive data indicators
        if any(sensitive in target_lower for sensitive in ['db', 'database', 'admin', 'api', 'payment', 'user']):
            exposure_score += 1
        
        return min(exposure_score, 3)
    
    def _assess_rce_potential(self, vuln_type: str, finding: Dict[str, Any]) -> bool:
        """Check if vulnerability enables remote code execution"""
        vuln_lower = vuln_type.lower()
        rce_indicators = ['rce', 'remote_code_execution', 'command_injection', 'code_injection', 'deserialization']
        
        return any(indicator in vuln_lower for indicator in rce_indicators)
    
    def _assess_lateral_movement(self, target: str, finding: Dict[str, Any]) -> int:
        """Assess lateral movement potential (0-2)"""
        target_lower = target.lower()
        
        # High lateral movement potential
        if any(high in target_lower for high in ['domain_controller', 'ad', 'ldap', 'network', 'router']):
            return 2
        
        # Medium lateral movement potential  
        if any(medium in target_lower for medium in ['server', 'database', 'service']):
            return 1
        
        return 0
    
    def _assess_exploit_chain_potential(self, vuln_type: str, finding: Dict[str, Any]) -> int:
        """Assess potential for exploit chaining (0-3)"""
        vuln_lower = vuln_type.lower()
        
        # High chain potential
        if any(high in vuln_lower for high in ['information_disclosure', 'ssrf', 'open_redirect']):
            return 3
        
        # Medium chain potential
        if any(medium in vuln_lower for medium in ['xss', 'csrf', 'file_upload']):
            return 2
        
        # Low chain potential  
        if any(low in vuln_lower for low in ['misconfiguration', 'weak_crypto']):
            return 1
        
        return 0
    
    def _generate_pentest_remediation(self, vuln_type: str, exploitability_level: str, finding: Dict[str, Any]) -> List[str]:
        """Generate pentest-specific remediation guidance"""
        remediation = []
        vuln_lower = vuln_type.lower()
        
        if exploitability_level == 'critical':
            remediation.append("IMMEDIATE ACTION: Disable affected service or implement emergency controls")
            remediation.append("Coordinate with security team for emergency response")
        
        # Vulnerability-specific remediation
        if 'sql_injection' in vuln_lower:
            remediation.extend([
                "Implement parameterized queries/prepared statements",
                "Apply input validation and sanitization",
                "Use least-privilege database accounts"
            ])
        elif 'xss' in vuln_lower:
            remediation.extend([
                "Implement output encoding/escaping",
                "Use Content Security Policy (CSP)",
                "Validate and sanitize user input"
            ])
        elif 'rce' in vuln_lower or 'command_injection' in vuln_lower:
            remediation.extend([
                "Disable code execution functionality if possible",
                "Implement strict input validation",
                "Use sandboxing/containerization",
                "Apply principle of least privilege"
            ])
        elif 'file_upload' in vuln_lower:
            remediation.extend([
                "Restrict file types and extensions",
                "Store uploads outside web root",
                "Implement virus scanning",
                "Validate file contents, not just extensions"
            ])
        
        return remediation
    
    def _get_remediation_priority(self, exploitability_level: str) -> str:
        """Get remediation priority based on exploitability"""
        priority_map = {
            'critical': 'IMMEDIATE',
            'high': 'URGENT', 
            'medium': 'HIGH',
            'low': 'MEDIUM'
        }
        return priority_map.get(exploitability_level, 'LOW')
    
    def _describe_pentest_impact(self, exploitability_level: str, vuln_type: str) -> str:
        """Describe the penetration testing impact"""
        if exploitability_level == 'critical':
            return f"Critical security vulnerability - {vuln_type} provides immediate path to compromise"
        elif exploitability_level == 'high':
            return f"High-risk vulnerability - {vuln_type} significantly increases attack success probability"
        elif exploitability_level == 'medium':
            return f"Moderate security risk - {vuln_type} could be exploited under certain conditions"
        else:
            return f"Low security risk - {vuln_type} has limited exploitation potential"
    
    def _generate_pentest_summary(self, stats: Dict[str, Any]) -> str:
        """Generate executive summary of penetration testing analysis"""
        total = stats['total_findings']
        critical = stats['critical_vulnerabilities']
        high = stats['high_risk_exploits']
        privesc = stats['privilege_escalations']
        auth_bypass = stats['authentication_bypasses']
        
        if critical > 0:
            summary = f"CRITICAL SECURITY ISSUES: {critical}/{total} vulnerabilities pose immediate exploitation risks. "
        elif high > 0:
            summary = f"HIGH-RISK VULNERABILITIES: {high}/{total} findings have high exploitation potential. "
        else:
            summary = "Penetration testing identified manageable security risks. "
        
        if privesc > 0:
            summary += f"Found {privesc} privilege escalation vectors. "
        if auth_bypass > 0:
            summary += f"Identified {auth_bypass} authentication bypass vulnerabilities. "
        
        summary += f"Overall business impact score: {stats['business_impact_score']}/10."
        
        return summary
    
    def _generate_pentest_action_plan(self, enhanced_findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Generate action plan for penetration testing findings"""
        actions = []
        
        # Group by exploitability level
        critical_vulns = [f for f in enhanced_findings if f.get('exploitability_level') == 'critical']
        high_vulns = [f for f in enhanced_findings if f.get('exploitability_level') == 'high']
        rce_vulns = [f for f in enhanced_findings if f.get('enables_rce', False)]
        privesc_vulns = [f for f in enhanced_findings if f.get('enables_privilege_escalation', False)]
        
        if critical_vulns:
            actions.append({
                'priority': 'IMMEDIATE',
                'action': 'Emergency response',
                'description': f'Address {len(critical_vulns)} critical vulnerabilities immediately',
                'timeline': 'Within 2 hours'
            })
        
        if rce_vulns:
            actions.append({
                'priority': 'URGENT',
                'action': 'Patch RCE vulnerabilities',
                'description': f'Fix {len(rce_vulns)} remote code execution vulnerabilities',
                'timeline': 'Within 24 hours'
            })
        
        if privesc_vulns:
            actions.append({
                'priority': 'HIGH',
                'action': 'Address privilege escalation',
                'description': f'Fix {len(privesc_vulns)} privilege escalation vulnerabilities',
                'timeline': 'Within 48 hours'
            })
        
        if high_vulns:
            actions.append({
                'priority': 'HIGH',
                'action': 'Vulnerability remediation',
                'description': f'Address {len(high_vulns)} high-risk vulnerabilities',
                'timeline': 'Within 1 week'
            })
        
        return actions
    
    async def run(self):
        """Run the MCP server"""
        async with stdio_server() as (read_stream, write_stream):
            await self.server.run(
                read_stream,
                write_stream,
                self.server.create_initialization_options()
            )

async def main():
    """Main entry point"""
    logging.basicConfig(level=logging.INFO)
    
    # Configure with authorized scope
    config = PentestConfig(
        target_scope=["authorized-target.com", "192.168.1.0/24"],
        test_intensity="safe",
        enable_exploits=False,  # Requires explicit permission
        log_all_attempts=True
    )
    
    server = PentestServer(config)
    await server.run()

if __name__ == "__main__":
    print("\n" + "="*60)
    print(" MCP Penetration Testing Server")
    print("="*60)
    print("\nThis is an MCP server that provides penetration testing")
    print("and vulnerability assessment tools.")
    print("\n  This server is waiting for MCP client connections...")
    print("It won't show any output when running correctly.\n")
    print("To get started:")
    print("  1. Run 'python setup_wizard.py' for guided setup")
    print("  2. Run 'python test_servers.py' to verify all servers work")
    print("  3. Configure Claude Desktop to use this server\n")
    print("Press Ctrl+C to stop the server.\n")
    print("-"*60 + "\n")
    
    asyncio.run(main())
